# Amirlahi Ademola Fajingbesi - Portfolio Knowledge Base

## Professional Summary

Amirlahi Ademola Fajingbesi is an experienced Data Scientist with 6 years of success in developing and implementing machine learning models, including pricing optimization and end-to-end management of data science products. He has a proven track record in leveraging advanced statistical techniques and driving data-driven decision-making to reduce costs and improve efficiencies across organizations.

Based in Bournemouth, United Kingdom, Amirlahi specializes in machine learning, data analysis, and building scalable data science solutions that deliver measurable business impact.

---

## Experience

### PlayMode Music - Data Scientist (August 2020 - Present)

**Current Role:** Data Scientist at PlayMode Music since August 2020.

**Key Achievements:**
- Led the development of machine learning models for **demand forecasting and pricing optimization**, resulting in a **30% improvement in streaming forecasts** and a **15% improvement in revenue growth**
- Collaborated with software engineers on functional APIs for real-time control to enhance data processing pipelines, **reducing processing time by 60%**
- Executed detailed data analysis through regression techniques, identifying correlations between user demographics and purchasing behavior
- Led to data-driven insights that improved marketing campaign effectiveness to **attract 40% more targeted customers**
- Created predictive models to optimize resource allocation, resulting in a **15% increase in revenue**
- Applied supervised and unsupervised learning algorithms to perform customer segmentation, resulting in a targeted marketing approach and a **20% increase in customer retention**

**Technologies Used:** Python, Machine Learning, Demand Forecasting, Pricing Optimization, Customer Segmentation, Regression Analysis, Data Analysis, Predictive Modeling

---

### PlayMode Music - Junior Data Scientist (October 2019 - August 2020)

**Role:** Junior Data Scientist at PlayMode Music from October 2019 to August 2020.

**Key Achievements:**
- Developed and implemented machine learning algorithms for customer churn prediction, resulting in a **30% decrease in churn rate**
- Conducted comprehensive exploratory data analysis and feature engineering, **improving model accuracy by 15%**
- Collaborated with software engineers to integrate machine learning models into production systems, **enhancing system efficiency by 20%**
- Supported A/B testing initiatives and performed statistical analysis on marketing campaigns, driving a **20% increase in conversion rates**
- Created visually appealing data visualizations and reports, facilitating data-driven decision-making by stakeholders

**Technologies Used:** Python, Machine Learning, Churn Prediction, Feature Engineering, Exploratory Data Analysis, A/B Testing, Statistical Analysis, Data Visualization, Production ML Systems

---

### Hype Multi-Media - Data Analyst (November 2016 - October 2019)

**Role:** Data Analyst at Hype Multi-Media from November 2016 to October 2019.

**Key Achievements:**
- Analysed customer data and identified patterns, driving a **10% improvement in customer engagement** and a **5% increase in sales**
- Engaged with diverse teams to build interactive visualisations and dashboards using Python and SQL, empowering data-driven decision-making across the organisation
- Conducted A/B testing experiments and performed statistical analysis, resulting in a **10% uplift in conversion rates** for marketing campaigns
- Contributed to the development of predictive models for customer churn forecasting, leading to a **15% reduction in customer attrition rates**
- Ensured data governance and compliance with privacy regulations through data governance initiatives, maintaining data integrity and privacy standards

**Technologies Used:** Python, SQL, Data Analysis, Customer Analytics, Data Visualization, Dashboards, A/B Testing, Predictive Modeling, Churn Forecasting, Data Governance, Privacy Compliance

---

## Education

### Bournemouth University - MSc Data Science & Artificial Intelligence (September 2022 - September 2023)

**Degree:** Master of Science (MSc) in Data Science & Artificial Intelligence

**Institution:** Bournemouth University, Bournemouth, United Kingdom

**Duration:** September 2022 to September 2023

Completed advanced studies in data science and artificial intelligence, covering machine learning, deep learning, natural language processing, computer vision, and advanced statistical methods.

---

### Olabisi Onabanjo University - BSc Statistics (September 2006 - August 2012)

**Degree:** Bachelor of Science (BSc) in Statistics

**Institution:** Olabisi Onabanjo University, Ogun State, Nigeria

**Duration:** September 2006 to August 2012

Completed undergraduate studies in statistics, covering statistical theory, probability, data analysis, and research methods.

---

## Skills

### Data Analysis

Amirlahi has strong data analysis capabilities including:
- **Accurate and complex analysis** of large datasets
- **Statistical interrogation** using advanced techniques
- **Hypothesis testing** and statistical inference
- Experience leveraging data analysis techniques to extract meaningful insights from complex datasets
- Skilled in exploratory data analysis (EDA) and identifying patterns in data

---

### Programming

**Python** (Advanced Level)
- Proficient in Python programming for data science, machine learning, and analytical tasks
- Extensive experience with Python libraries and frameworks
- Production-level Python code development

**SQL** (Proficient)
- Working knowledge of SQL for database querying and data manipulation
- Experience with data extraction, transformation, and loading (ETL)

---

### Machine Learning

Amirlahi has extensive expertise in machine learning including:
- **Deep Learning Models** and neural network architectures
- **Natural Language Processing (NLP)** for text analytics
- **Predictive Modelling** for forecasting and optimization
- **Supervised Learning** algorithms (regression, classification)
- **Unsupervised Learning** algorithms (clustering, dimensionality reduction)
- Experience with **scikit-learn**, **Keras**, and other ML frameworks
- **ARIMA models** for time series forecasting
- Development of end-to-end ML solutions from research to production

---

### Data Wrangling

- Experience in **data wrangling** and data preprocessing
- **Feature engineering** to improve model performance
- Skilled at transforming raw data into clean, structured formats suitable for analysis and modeling
- Data cleaning and handling missing values
- Data transformation and normalization

---

### Data Visualization

- Strong **visual communication** and data visualization skills
- Proficient in creating clear, impactful visualizations
- Effective communication of complex data insights to both technical and non-technical stakeholders
- Dashboard creation and interactive visualizations
- Experience presenting data stories to stakeholders

---

### Tools and Technologies

Amirlahi is experienced with a comprehensive toolkit of data science tools:

**Development Environments:**
- Jupyter Notebook
- Python IDEs

**Data Processing:**
- Apache Spark (distributed computing)
- Pandas (data manipulation)
- NumPy (numerical computing)

**Machine Learning:**
- Scikit-learn
- Keras
- TensorFlow
- PyTorch

**Visualization:**
- Matplotlib
- Seaborn
- Interactive visualization libraries

**Databases:**
- SQL databases
- Data querying and management

---

### Statistical Models

Expertise in various statistical models and techniques:
- **Reinforcement Learning** for sequential decision-making
- **Demand Forecasting** using time series models
- **Generalised Linear Models (GLM)** for regression analysis
- **Recommendation Systems** for personalization
- **Content-Based Filtering** for recommendation engines
- **Clustering** algorithms (K-means, hierarchical clustering)
- **Principal Component Analysis (PCA)** for dimensionality reduction
- **Time Series Analysis** and forecasting methods

---

### Soft Skills

**Presentation and Storytelling:**
- Strong presentation abilities
- Capacity to explain technical concepts to both technical and non-technical stakeholders
- Data storytelling and narrative creation

**Collaboration:**
- Experience collaborating on projects within a team
- Excellent communication skills
- Cross-functional teamwork with engineers, product managers, and business stakeholders

**Problem-Solving:**
- Analytical thinking and problem-solving approach
- Data-driven decision-making
- Business acumen and understanding of organizational impact

---

## Contact Information

**Name:** Amirlahi Ademola Fajingbesi

**Location:** Bournemouth, United Kingdom

**Phone:** 07765624800

**Email:** adescofaj@gmail.com

**LinkedIn:** https://www.linkedin.com/in/adescofaj/

**GitHub:** https://github.com/adescofaj

**Professional Title:** Data Scientist

**Years of Experience:** 6+ years in data science and machine learning

---


## Projects

### Customer-Segmentation

**Repository:** [Customer-Segmentation](https://github.com/adescofaj/Customer-Segmentation)

**Description:** Customer analytics project applying K-Means clustering to retail data for market segmentation and personalized marketing strategy development.

**Primary Language:** Jupyter Notebook

**Project Details:**

# Customer Segmentation

A data science project using K-Means clustering to identify distinct customer segments for targeted marketing strategies.

### Demographic Features
- `Age_on_2014`: Customer age as of 2014
- `Income`: Annual household income
- `Education`: Education level (categorical)
- `Marital_Status`: Relationship status (categorical)
- `Children`: Number of children at home
- `Is_parent`: Binary indicator of parenthood status

### Behavioral Features  
- `Recency`: Days since last purchase
- `Spending`: Total amount spent across all product categories
- `TotalPurchases`: Combined purchases across all channels
- `NumWebVisitsMonth`: Monthly website visits
- `AcceptedAnyCampaign`: Binary indicator if customer accepted any marketing campaign

### Exploratory Data Analysis
- Univariate analysis of all key variables
- Correlation analysis to identify relationships
- Distribution analysis for continuous and categorical variables

### Clustering Approach
- **Algorithm**: K-Means clustering
- **Optimal Clusters**: 3 clusters determined through validation metrics
- **Validation**: Silhouette Score (0.502) and Davies-Bouldin Score (0.793)

### Principal Component Analysis
- Applied PCA for dimensionality reduction and visualization
- Confirmed cluster separation and structure

### Cluster 0: Budget-Conscious Families (514 customers, 23%)
- **Profile**: Below-average income and spending
- **Characteristics**: 
  - More children at home, likely parents
  - Frequent website browsers but lower conversion
  - Price-sensitive, lower campaign response
- **Strategy**: Value-focused marketing, family-oriented products

### Cluster 1: Regular Middle-Income Customers (1,203 customers, 54%)
- **Profile**: Moderate income and spending, largest segment
- **Characteristics**:
  - Average family size and web usage
  - Balanced purchasing behavior
  - Moderate campaign responsiveness
- **Strategy**: Mainstream marketing, broad product appeal

### Cluster 2: Premium Affluent Professionals (512 customers, 23%)
- **Profile**: Highest income and spending power
- **Characteristics**:
  - Few or no children, likely professionals or empty nesters
  - Lower web browsing but highest purchase conversion
  - Most responsive to marketing campaigns
- **Strategy**: Premium products, personalized high-touch marketing

### Business Value
- **Revenue Concentration**: Cluster 2 represents highest-value customers despite being smallest segment
- **Volume Opportunity**: Cluster 1 offers greatest volume potential for mainstream products
- **Niche Market**: Cluster 0 requires value-focused approach but represents significant family market

### Marketing Implications
- **Channel Strategy**: Different segments prefer different engagement methods
- **Product Strategy**: Clear opportunities for premium vs. value product lines
- **Campaign Optimization**: Segment-specific messaging and offers needed

### Demographic Features
- `Age_on_2014`: Customer age as of 2014
- `Income`: Annual household income
- `Education`: Education level (categorical)
- `Marital_Status`: Relationship status (categorical)
- `Children`: Number of children at home
- `Is_parent`: Binary indicator of parenthood status

### Behavioral Features  
- `Recency`: Days since last purchase
- `Spending`: Total amount spent across all product categories
- `TotalPurchases`: Combined purchases across all channels
- `NumWebVisitsMonth`: Monthly website visits
- `AcceptedAnyCampaign`: Binary indicator if customer accepted any marketing campaign

### Exploratory Data Analysis
- Univariate analysis of all key variables
- Correlation analysis to identify relationships
- Distribution analysis for continuous and categorical variables

### Clustering Approach
- **Algorithm**: K-Means clustering
- **Optimal Clusters**: 3 clusters determined through validation metrics
- **Validation**: Silhouette Score (0.502) and Davies-Bouldin Score (0.793)

### Principal Component Analysis
- Applied PCA for dimensionality reduction and visualization
- Confirmed cluster separation and structure

### Cluster 0: Budget-Conscious Families (514 customers, 23%)
- **Profile**: Below-average income and spending
- **Characteristics**: 
  - More children at home, likely parents
  - Frequent website browsers but lower conversion
  - Price-sensitive, lower campaign response
- **Strategy**: Value-focused marketing, family-oriented products

### Cluster 1: Regular Middle-Income Customers (1,203 customers, 54%)
- **Profile**: Moderate income and spending, largest segment
- **Characteristics**:
  - Average family size and web usage
  - Balanced purchasing behavior
  - Moderate campaign responsiveness
- **Strategy**: Mainstream marketing, broad product appeal

### Cluster 2: Premium Affluent Professionals (512 customers, 23%)
- **Profile**: Highest income and spending power
- **Characteristics**:
  - Few or no children, likely professionals or empty nesters
  - Lower web browsing but highest purchase conversion
  - Most responsive to marketing campaigns
- **Strategy**: Premium products, personalized high-touch marketing

### Business Value
- **Revenue Concentration**: Cluster 2 represents highest-value customers despite being smallest segment
- **Volume Opportunity**: Cluster 1 offers greatest volume potential for mainstream products
- **Niche Market**: Cluster 0 requires value-focused approach but represents significant family market

### Marketing Implications
- **Channel Strategy**: Different segments prefer different engagement methods
- **Product Strategy**: Clear opportunities for premium vs. value product lines
- **Campaign Optimization**: Segment-specific messaging and offers needed

### Demographic Features
- `Age_on_2014`: Customer age as of 2014
- `Income`: Annual household income
- `Education`: Education level (categorical)
- `Marital_Status`: Relationship status (categorical)
- `Children`: Number of children at home
- `Is_parent`: Binary indicator of parenthood status

### Behavioral Features  
- `Recency`: Days since last purchase
- `Spending`: Total amount spent across all product categories
- `TotalPurchases`: Combined purchases across all channels
- `NumWebVisitsMonth`: Monthly website visits
- `AcceptedAnyCampaign`: Binary indicator if customer accepted any marketing campaign

### Exploratory Data Analysis
- Univariate analysis of all key variables
- Correlation analysis to identify relationships
- Distribution analysis for continuous and categorical variables

### Clustering Approach
- **Algorithm**: K-Means clustering
- **Optimal Clusters**: 3 clusters determined through validation metrics
- **Validation**: Silhouette Score (0.502) and Davies-Bouldin Score (0.793)

### Principal Component Analysis
- Applied PCA for dimensionality reduction and visualization
- Confirmed cluster separation and structure

### Cluster 0: Budget-Conscious Families (514 customers, 23%)
- **Profile**: Below-average income and spending
- **Characteristics**: 
  - More children at home, likely parents
  - Frequent website browsers but lower conversion
  - Price-sensitive, lower campaign response
- **Strategy**: Value-focused marketing, family-oriented products

### Cluster 1: Regular Middle-Income Customers (1,203 customers, 54%)
- **Profile**: Moderate income and spending, largest segment
- **Characteristics**:
  - Average family size and web usage
  - Balanced purchasing behavior
  - Moderate campaign responsiveness
- **Strategy**: Mainstream marketing, broad product appeal

### Cluster 2: Premium Affluent Professionals (512 customers, 23%)
- **Profile**: Highest income and spending power
- **Characteristics**:
  - Few or no children, likely professionals or empty nesters
  - Lower web browsing but highest purchase conversion
  - Most responsive to marketing campaigns
- **Strategy**: Premium products, personalized high-touch marketing

### Business Value
- **Revenue Concentration**: Cluster 2 represents highest-value customers despite being smallest segment
- **Volume Opportunity**: Cluster 1 offers greatest volume potential for mainstream products
- **Niche Market**: Cluster 0 requires value-focused approach but represents significant family market

### Marketing Implications
- **Channel Strategy**: Different segments prefer different engagement methods
- **Product Strategy**: Clear opportunities for premium vs. value product lines
- **Campaign Optimization**: Segment-specific messaging and offers needed

### Heart-Disease-Prediction

**Repository:** [Heart-Disease-Prediction](https://github.com/adescofaj/Heart-Disease-Prediction)

**Description:** Machine learning model for heart disease prediction using clinical patient data. Complete ML pipeline with data preprocessing, multiple algorithms, and performance evaluation. Built with Python and scikit-learn.

**Primary Language:** Jupyter Notebook

**Project Details:**

# Heart Disease Prediction Using Machine Learning

### Key Features
- **Demographics**: Age, gender
- **Clinical Measurements**: Blood pressure, cholesterol, max heart rate
- **Symptoms**: Chest pain type, exercise-induced angina
- **Diagnostic Tests**: ECG results, ST depression, vessel count, thalassemia

### Feature Engineering
- **Ordinal Encoding**: Applied to chest pain, ST slope, vessel count
- **One-Hot Encoding**: Applied to nominal categories (gender, blood sugar, etc.)
- **Scaling**: StandardScaler applied to continuous variables
- **Balancing**: SMOTE used to address class imbalance

### Models Implemented
- Logistic Regression
- Support Vector Machine (SVM)
- K-Nearest Neighbors (KNN)
- Decision Tree
- Random Forest
- AdaBoost
- Gradient Boosting
- CatBoost
- XGBoost
- LightGBM

### Evaluation Metrics
- Accuracy, Precision, Recall, F1-Score
- Confusion Matrix visualization

### Installation
```bash
pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn
```

### Usage
```bash
git clone https://github.com/yourusername/heart-disease-prediction.git
cd heart-disease-prediction
jupyter notebook heart_disease_prediction.ipynb
```

### Model Performance Comparison
| Model | Train Accuracy | Test Accuracy | Test Recall | Test Precision | AUC | Clinical Assessment |
|-------|----------------|---------------|-------------|----------------|-----|-------------------|
| **Logistic Regression** ‚úÖ | 85.4% | 81.9% | 84.4% | 92.9% | 89% | **SELECTED** |
| Decision Tree | 100% | 82.7% | 87.3% | 91.2% | 74% | Overfitted |
| XGBoost | 99.3% | 82.1% | 86.3% | 91.4% | 89% | Overfitted |

### Python-Coding-Assistant

**Repository:** [Python-Coding-Assistant](https://github.com/adescofaj/Python-Coding-Assistant)

**Description:** An AI-powered Python coding assistant built with LangGraph, LangChain, and GPT-4o Mini ‚Äî designed for code explanation, debugging, and programming assistance.

**Primary Language:** JavaScript

**Project Details:**

# ü§ñ Python AI Assistant - LangGraph Workflow Engine

An intelligent Python programming assistant powered by **LangGraph**, **LangChain**, and **OpenAI GPT-4o Mini**. Built with a multi-node workflow architecture for specialized code analysis, debugging, and programming assistance.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![LangGraph](https://img.shields.io/badge/LangGraph-Latest-FF6B6B.svg)
![LangChain](https://img.shields.io/badge/LangChain-Latest-1C1C1C.svg)
![OpenAI](https://img.shields.io/badge/OpenAI-GPT4o_Mini-412991.svg)

### **LangGraph Workflow**
```
START ‚Üí Router ‚Üí [EXPLAIN | DEBUG | GENERAL] ‚Üí Response ‚Üí END
```

- **Router Node**: Classifies and routes requests
- **Explain Node**: Code analysis and educational explanations  
- **Debug Node**: Error detection and solution generation
- **General Node**: Conversational programming assistance

### **Memory Management**
```python
# Thread-based conversation memory
{
    "thread_id": {
        "memory": ConversationBufferMemory(),
        "last_code": Optional[str]
    }
}
```

### **Model Configuration**
```python
llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0.3,
    max_tokens=500
)
```

### **Explain Node**
- Code syntax breakdown and analysis
- Algorithm explanation with step-by-step walkthrough
- Best practices identification

### **Debug Node** 
- Syntax and logic error detection
- Performance issue identification
- Solution generation with corrected code

### **General Node**
- Natural language programming assistance
- Concept explanations and best practices
- Casual programming conversation

### **Backend**
```bash
# Install dependencies
pip install fastapi uvicorn langchain langchain-openai langgraph python-dotenv

# Environment setup
echo "OPENAI_API_KEY=your-key" > .env

# Run server
uvicorn main:app --reload
```

### **Frontend**
```bash
# Install dependencies  
npm install react-ace ace-builds react-markdown react-syntax-highlighter

# Start app
npm start
```

### Research-Summarizer

**Repository:** [Research-Summarizer](https://github.com/adescofaj/Research-Summarizer)

**Description:** AI research paper summarizer using GPT-4o-mini, and FastAPI. Intelligent document processing with customizable summaries and token optimization for cost-effective operation.

**Primary Language:** JavaScript

**Project Details:**

# Research Paper Summarizer

AI-powered tool that automatically generates summaries of research papers using GPT-4o-mini and intelligent document processing.

### Backend
```bash
cd ai_engine
pip install -r requirements.txt
echo "OPENAI_API_KEY=your_key" > .env
uvicorn app:app --reload
```

### Frontend
```bash
cd frontend  
npm install
echo "VITE_API_BASE_URL=http://127.0.0.1:8000" > .env
npm run dev
```

### Tech-Training-Analytics

**Repository:** [Tech-Training-Analytics](https://github.com/adescofaj/Tech-Training-Analytics)

**Description:** This project showcases a realistic data analytics workflow for a corporate tech training platform. It demonstrates systematic data quality assessment, comprehensive cleaning procedures, database design, and strategic business analytics

**Primary Language:** N/A

**Project Details:**

# Tech Training Platform Database Analytics

A complete data analyst project demonstrating end-to-end skills from messy data to business insights.

### Database Design
- Normalized relational database structure
- Foreign key constraints and referential integrity
- Realistic business entity modeling

### Data Quality & Cleaning
- Systematic data quality assessment
- Standardized data formats and conventions
- Comprehensive cleaning procedures with validation

### Business Analytics
- Strategic KPI identification
- Revenue and performance analysis
- Student engagement and retention insights

### Financial Performance
- **Total Revenue:** $11,199.76
- **Completion Rate:** 85.7%
- **Average Student Score:** 87.30

### Top Performers
- **Highest Revenue Course:** Ethical Hacking ($2,399.97)
- **Most Popular Instructor:** Sarah Chen (Python Development)
- **Most Valuable Tier:** Corporate subscriptions(11)

### Strategic Findings
- Advanced courses generate 2x higher revenue per student
- Desktop learning sessions show highest completion rates
- Corporate clients demonstrate strongest engagement patterns

### Before Cleaning
| Table | Total Records | Quality Issues | Issue Rate |
|-------|---------------|----------------|------------|
| Instructors | 7 | 2 | 28.6% |
| Students | 25 | 12 | 48.0% |
| Courses | 9 | 4 | 44.4% |
| Enrollments | 30 | 6 | 20.0% |
| Learning Sessions | 55 | 15 | 27.3% |

### After Cleaning
**Result: 0% data quality issues across all tables**

Common issues resolved:
- Case inconsistencies (`individual` ‚Üí `Individual`)
- Format variations (`90 mins` ‚Üí `90 minutes`)
- Invalid data markers (`null`, `N/A` ‚Üí proper NULL values)
- Incomplete entries (missing email domains, company names)

### Routing-Optimisation-for-Aeronautical-Networks

**Repository:** [Routing-Optimisation-for-Aeronautical-Networks](https://github.com/adescofaj/Routing-Optimisation-for-Aeronautical-Networks)

**Description:** ROUTING-OPTIMISATION-FOR-AERONAUTICAL-NETWORKS

**Primary Language:** Jupyter Notebook

**Project Details:**

ROUTING OPTIMISATION FOR AERONAUTICAL NETWORKS
ABSTRACT

With a growing demand for internet access among passenger airplanes, aeronautical ad-hoc networks (AANETs) have stepped up to meet this demand. But there is a limited transmission, and it is quite expensive to transmit the internet. To provide this, there needs to be an optimal routing path to a ground station (GS). The end-to-end data transmission rate and end-to-end latency are very important to determine the optimal data packet route. Passenger airplanes can also serve as mobile ground stations. In this paper, we have two objectives. A single objective of finding a route that has the maximum end-to-end data transmission rate among airplanes that can connect to ground stations and multiple objectives of finding the maximum end-to-end data transmission rate with a minimum end-to-end latency for all airplanes that can connect to ground stations. Two algorithms are deployed to solve this problem, the A-star algorithm, and the Ant Colony algorithm. It was concluded that A-star has the shortest routing path, but ACO shows more reliability in terms of performance.
INTRODUCTION

When collecting quantitative methods used in decision-making and physical system analysis at individual and communal levels, optimization is a very important technique. To implement this technique, it is very important to make a quantitative assessment of the performance of the system under exploration, which is the objective. This objective is determined by certain features of the system, these are called variables, and are usually unknown (Nocedal and Wright 2006). The values of a group of independent variables that minimize a known value objective function are deduced by optimization (Hocking et al. 2002). Mathematically, optimization is the minimization or maximization of a function subject to constraints on its variables (Brownlee 2021).
Modelling is the process of establishing the objectives, variables, and constraints for a specific task. The first step in the optimization process‚Äîand occasionally the most crucial step‚Äîis the creation of a suitable model (Nocedal and Wright 2006). Function optimization is the problem of finding the set of inputs to a target objective function that results in the minimum or maximum of the function.
Local or global optimization is a common way to describe optimization issues. Techniques for local and global optimization Investigate various options to find the best solution. In general, local optimization techniques are ‚Äúgreedier‚Äù because they tend to ignore other search spaces in favour of going down the most promising path already established. This kind of optimization ought to work better for straightforward systems with a limited number of well-defined variables that need to be optimized.
Despite its likeliness to take more time, global optimization concentrates on locating the route to the best potential solution throughout the entire search space. This enables the development of more trustworthy solutions, though it might take a little longer to get there. This could be a good strategy to use if the system's various variables have an unknowable relationship to one another or if the system is more complicated or a "black box."
PROBLEM
Even as all wireless generation systems have improved in transmission and throughput, there has only been a focus on traditional coverage, hence the improvement and predictions for higher profit margins for service providers. 5G wireless system is now able to transmit between 100 Megabits-per-second (Mbps) and 20 Gigabits-per-second (Gbps) at peak times. However, passenger airplanes have limited internet access, and are also expensive.

This has brought the emergence of aeronautical ad-hoc networks (AANETs) to provide internet to airplanes (Zhang et al. 2021). Passenger airplanes can also be used as mobile ground stations to provide internet to places that are difficult to transmit and maintain wireless provision. To provide Internet access to passengers onboard, each airplane needs to find an optimal data packet routing path to a ground station (GS) in terms of one or two more objectives to be optimized.
 
Figure 1: Airplanes connecting from ground stations.

To find an optimal data packet routing path, there are two metrics to be considered, end-to-end data transmission rate and end-to-end latency. The end-to-end latency is the sum of all delays imposed by each link (passenger airplanes) and is traditionally calculated in milliseconds (Ms) while the end-to-end data transmission rate is the minimum transmission rate of each link (passenger airplanes) in the routing path, which is calculated in megabits-per-second (Mbps).
 
Figure 2: Latency is the delay (time in between) imposed by each connecting airplane.
 
Figure 3: The end-to-end latency is the sum of all delays imposed by each link (85ms)

 
Figure 4: End-to-End Data Transmission Rate is the minimum transmission rate of each link in the routing path (5m^2/h)

The transmission rate of a link is determined by the distance between a pair of communicating airplanes which are given in the table in (Fig 5). With 740 km being the maximum switching threshold. If the distance between a pair of communication airplanes is 200km, so 190km < 200km < 300km, the data transmission rate between both airplanes will be 63.970 Mbps. If the distance is 680km, then 500km < 680km < 740km, the data transmission rate between them will be 31.895 Mbps. For more than 740km, there will be no data transmission.
 
Figure 5: Data Transmission Rate
The locations of the communicating airplanes are represented in 3D Cartesian coordinates and the distance between a pair of airplanes is given as:
 
Figure 6: Where "Px,a", "Py,a" and "Pz,a" are the 3D Cartesian coordinates of a pair of communicating airplanes, while "Px,b", "Py,b" and "Pz,b" are those of the other pair of communicating airplanes.

OPTIMIZATION PROBLEMS

1.	Single-objective optimization: Finding a routing path having the maximum end-to-end data transmission rate for each airplane that can access any of a GS, either at Heathrow Airport (LHR) (Latitude, Longitude, Altitude) = (51.4700¬∞ N, 0.4543¬∞ W, 81.73 feet) or Newark Liberty International Airport (EWR) (Latitude, Longitude, Altitude) = (40.6895¬∞ N, 74.1745¬∞ W, 8.72 feet).
2.	Multiple-objective optimization: Finding a routing path having the maximum end-to-end data transmission rate and minimum end-to-end latency for each airplane that can access any of a GS, either at Heathrow airport (Latitude, Longitude, Altitude) = (51.4700¬∞ N, 0.4543¬∞ W, 81.73 feet) or Newark Liberty International Airport (Latitude, Longitude, Altitude) = (40.6895¬∞ N, 74.1745¬∞ W, 8.72 feet).

METHODOLOGY

Two optimization algorithms will be implemented in solving these two problems, they are the ‚ÄúAnt Colony‚Äù and the ‚ÄúA-star‚Äù optimization algorithm respectively.

Ant colony optimization algorithms (ACO)
ACO is a population-based search technique influenced by ant behaviour for resolving multimodal optimization issues. Naturally, some ant species roam at first, then return to their colony after locating food as well as leaving pheromone trails. If other ants discover such a route, they are more likely to follow it rather than continue moving at random, revisiting and strengthening the pheromone trails if they subsequently find food. The shorter the distance, the longer the pheromone trail lasts, and as more ants follow the pheromone trail, the longer the trail lasts because they all will be leaving trails.
Because the pheromone levels are equal in the first cycle, the decisions are based on distances and some noise. On the way back all ants or the selected number of best ants deposit pheromones on the paths they travelled, this is done to encourage ants to give more priority to shorter routes.

A-Star Algorithm
A-star is a graph traversal and route search algorithm that is widely used in computer science because of its thoroughness and allocative efficiency. A-star is a best-first search method that is written in terms of weighted graphs. It starts at a particular starting node in a network and seeks to find the shortest path to the specified goal node (end-to-end transmission rate, shortest distance, etc.). It accomplishes this by keeping track of a tree of paths leading from the start node and extending each of those paths by one edge until its termination requirement is met (Wikipedia Contributors 2019).
It must decide which of its paths to extend to for every iteration of its main loop. It bases its decision on the cost of the path as well as an estimate of the cost of extending the path leading to the target. A-star does this by choosing the path that minimizes ‚Äúf(n) = g(n) + h(n)‚Äù, where n is the subsequent node on the path, g(n) is the cost of the path from the first node to n, and h(n) is an objective function that estimates the cost of the cheapest path from n to the destination. The iteration ends when the path it selects to extend is a path from beginning to destination, or when there are no paths qualified for an extension. If the objective function does not exceed the real cost of getting to the destination, A-star will always return the minimum cost path from start to destination.

CONCLUSION

A-Star has the shortest routing path with an average delay of 222.22ms and an average data transmission rate of 35.40Mbps, but ACO shows more reliability in terms of performance with a higher average data transmission rate of 48.42Mbps but an average delay of 799.07ms.





Reference list
Brownlee, J., 2021. Local Optimization Versus Global Optimization [online]. MachineLearningMastery.com. Available from: https://machinelearningmastery.com/local-optimization-versus-global-optimization/#:~:text=Local%20optimization%20involves%20finding%20the.
Hocking, D., Nougu√©s, J. M., Rodr√≠guez, J. C. and Sama, S., 2002. Chapter 3.3 - Simulation, Design & Analysis [online]. ScienceDirect. Available from: https://www.sciencedirect.com/science/article/abs/pii/S1570794602800104 [Accessed 12 Jan 2023].
Nocedal, J. and Wright, S. J., 2006. Introduction. Springer Series in Operations Research and Financial Engineering, 1‚Äì9.
Wikipedia Contributors, 2019. A* search algorithm [online]. Wikipedia. Available from: https://en.wikipedia.org/wiki/A.
Zhang, J., Xiang, L., Liu, D., Cui, J., Ng, S. X., Maunder, R. G., Graeupl, T., Carsten-Fiebig, U. and Hanzo, L., 2021. Semi-Stochastic Aircraft Mobility Modelling for Aeronautical Networks: An Australian Case-Study Based on Real Flight Data. IEEE Transactions on Vehicular Technology [online], 70 (10), 10763‚Äì10779. Available from: https://ieeexplore.ieee.org/document/9511787 [Accessed 12 Jan 2023].



---
## Additional Information

<!-- This section will be populated with LinkedIn profile data and other relevant information -->
